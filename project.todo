# TinyTokenizer Improvement Plan - Project Tasks
# Based on: docs/improvement-plan-2026.md
# Created: January 2, 2026
# Target Completion: Q2 2026

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 1: Quick Wins (v0.6.6)
Timeline: 1-2 days | Breaking Changes: None
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[ ] 1.1 Pre-compute Comment Style Flags (30 min)
    File: TokenParser.cs
    â”œâ”€[ ] Add _hasCSingleLineComment private readonly field
    â”œâ”€[ ] Add _hasCMultiLineComment private readonly field
    â”œâ”€[ ] Initialize fields in constructor from options.CommentStyles
    â”œâ”€[ ] Update TryParseComment to use cached fields instead of LINQ
    â”œâ”€[ ] Verify no LINQ allocation in TryParseComment
    â””â”€[ ] Benchmark comment-heavy input to confirm improvement

[ ] 1.2 Add IFormattable to Token (1 hr)
    File: Token.cs
    â”œâ”€[ ] Add IFormattable interface to base Token record
    â”œâ”€[ ] Implement ToString(string?, IFormatProvider?) method
    â”‚     â”œâ”€[ ] "G" or null â†’ ContentSpan.ToString()
    â”‚     â”œâ”€[ ] "T" â†’ Type.ToString()
    â”‚     â”œâ”€[ ] "P" â†’ Position.ToString()
    â”‚     â”œâ”€[ ] "R" â†’ Range format "{Position}..{Position + Content.Length}"
    â”‚     â””â”€[ ] "D" â†’ Debug format "{Type}[{Range}]"
    â”œâ”€[ ] Add XML documentation for format specifiers
    â””â”€[ ] Add unit tests for each format specifier

[ ] 1.3 Fix AppendToBuffer Inefficiency (15 min)
    File: TokenParser.cs
    â”œâ”€[ ] Add EnsureCapacity call before loop
    â”œâ”€[ ] Replace indexed access with foreach over span
    â”œâ”€[ ] Verify single capacity allocation instead of multiple resizes
    â””â”€[ ] Run all parsing tests to confirm no regressions

[ ] 1.4 Cache SiblingIndex in RedNode (1 hr)
    File: Ast/RedNode.cs
    â”œâ”€[ ] Add private readonly int _siblingIndex field
    â”œâ”€[ ] Update internal constructor to accept siblingIndex parameter (default -1)
    â”œâ”€[ ] Update GetRedChild<T> to pass slot index when creating red child
    â”œâ”€[ ] Update CreateRed method signature to accept siblingIndex
    â”œâ”€[ ] Change SiblingIndex property to return _siblingIndex directly
    â”œâ”€[ ] Verify O(1) access time
    â””â”€[ ] Test NextSibling() and PreviousSibling() still work correctly

[ ] 1.5 Phase 1 Release
    â”œâ”€[ ] Run full test suite (dotnet test)
    â”œâ”€[ ] Run benchmarks and document results
    â”œâ”€[ ] Update CHANGELOG.md with changes
    â”œâ”€[ ] Bump version to 0.6.6 in TinyTokenizer.csproj
    â”œâ”€[ ] Commit and tag as v0.6.6
    â”œâ”€[ ] Create GitHub release
    â””â”€[ ] Verify NuGet package published via CI

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 2: Performance (v0.7.0)
Timeline: 1-2 weeks | Breaking Changes: Minor (internal APIs only)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[ ] 2.1 Replace List<char> with ArrayPoolBufferWriter (4 hrs)
    Files: TokenParser.cs, TinyTokenizer.csproj
    â”œâ”€[ ] Add NuGet reference: CommunityToolkit.HighPerformance 8.2.2
    â”œâ”€[ ] Add using CommunityToolkit.HighPerformance.Buffers
    â”œâ”€[ ] Update ParseBlock method
    â”‚     â”œâ”€[ ] Replace List<char> with ArrayPoolBufferWriter<char>
    â”‚     â”œâ”€[ ] Use buffer.Write(span) for appending
    â”‚     â””â”€[ ] Add using statement for proper disposal
    â”œâ”€[ ] Update ParseString method
    â”‚     â”œâ”€[ ] Replace List<char> with ArrayPoolBufferWriter<char>
    â”‚     â””â”€[ ] Ensure disposal in all code paths
    â”œâ”€[ ] Update ParseNumericFromDigits method
    â”œâ”€[ ] Update ParseNumericFromDot method
    â”œâ”€[ ] Update ParseSingleLineComment method
    â”œâ”€[ ] Update ParseMultiLineComment method
    â”œâ”€[ ] Update TryParseOperator method
    â”œâ”€[ ] Update TryParseTaggedIdent method
    â”œâ”€[ ] Remove AppendToBuffer helper method (no longer needed)
    â”œâ”€[ ] Run allocation benchmark (target: >50% reduction)
    â””â”€[ ] Verify no memory leaks with memory profiler

[ ] 2.2 Build Operator Trie (6 hrs)
    Files: TokenParser.cs, new OperatorTrie.cs
    â”œâ”€[ ] Create OperatorTrie.cs file
    â”‚     â”œâ”€[ ] Create internal sealed class OperatorTrie
    â”‚     â”œâ”€[ ] Create private sealed class TrieNode
    â”‚     â”‚     â”œâ”€[ ] Dictionary<char, TrieNode>? Children
    â”‚     â”‚     â””â”€[ ] string? Operator (non-null if end of operator)
    â”‚     â”œâ”€[ ] Implement Add(string op) method
    â”‚     â””â”€[ ] Implement TryMatch(ReadOnlySpan<char>) method
    â”œâ”€[ ] Update TokenParser constructor
    â”‚     â”œâ”€[ ] Add private readonly OperatorTrie _operatorTrie field
    â”‚     â””â”€[ ] Build trie from options.Operators
    â”œâ”€[ ] Update TryParseOperator to use trie lookup
    â”œâ”€[ ] Verify O(k) matching where k = operator length
    â”œâ”€[ ] Verify greedy matching still works (longest match first)
    â”œâ”€[ ] Add unit tests for OperatorTrie
    â””â”€[ ] Benchmark with 50+ operators to confirm improvement

[ ] 2.3 Standardize Position Types (2 hrs) âš ï¸ BREAKING
    Files: SimpleToken.cs, Token.cs, all derived types
    â”œâ”€[ ] Update SimpleToken.cs
    â”‚     â””â”€[ ] Change Position parameter: long â†’ int
    â”œâ”€[ ] Update Token.cs
    â”‚     â””â”€[ ] Change Position parameter: long â†’ int
    â”œâ”€[ ] Update all derived token types (if any explicit Position usage)
    â”œâ”€[ ] Update Lexer.cs position tracking
    â”œâ”€[ ] Update TokenParser.cs position handling
    â”œâ”€[ ] Search codebase for all long position usages and update
    â”œâ”€[ ] Add XML doc noting 2GB file size practical limit
    â”œâ”€[ ] Update all tests with position assertions
    â””â”€[ ] Document breaking change in CHANGELOG

[ ] 2.4 Pre-sort Operators in TokenizerOptions (1 hr)
    File: TokenizerOptions.cs
    â”œâ”€[ ] Change Operators property type: ImmutableHashSet<string> â†’ ImmutableArray<string>
    â”œâ”€[ ] Update Default static property initialization
    â”œâ”€[ ] Update WithOperators method
    â”‚     â”œâ”€[ ] Apply Distinct() to remove duplicates
    â”‚     â”œâ”€[ ] Apply OrderByDescending(op => op.Length)
    â”‚     â””â”€[ ] Convert to ImmutableArray
    â”œâ”€[ ] Remove sorting from TokenParser constructor
    â””â”€[ ] Verify existing public API behavior unchanged

[ ] 2.5 Phase 2 Release
    â”œâ”€[ ] Run full test suite
    â”œâ”€[ ] Run before/after allocation benchmarks
    â”œâ”€[ ] Document benchmark results
    â”œâ”€[ ] Write migration guide for position type change (long â†’ int)
    â”œâ”€[ ] Update CHANGELOG.md with all changes and breaking changes
    â”œâ”€[ ] Bump version to 0.7.0 in TinyTokenizer.csproj
    â”œâ”€[ ] Commit and tag as v0.7.0
    â”œâ”€[ ] Create GitHub release with migration notes
    â””â”€[ ] Verify NuGet package published via CI

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 3: API Cleanup (v0.8.0)
Timeline: 2-3 weeks | Breaking Changes: Yes (major cleanup)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[ ] 3.1 Consolidate Duplicate Parsing Logic (8 hrs)
    Files: Tokenizer.cs, TokenParser.cs, Ast/GreenLexer.cs, new ParsingCore.cs
    â”œâ”€[ ] Create ParsingCore.cs file
    â”‚     â”œâ”€[ ] Create internal static class ParsingCore
    â”‚     â””â”€[ ] Define ParseResult readonly struct
    â”‚           â”œâ”€[ ] ReadOnlyMemory<char> Content
    â”‚           â”œâ”€[ ] int ConsumedTokens
    â”‚           â”œâ”€[ ] bool Success
    â”‚           â””â”€[ ] string? ErrorMessage
    â”œâ”€[ ] Implement shared parsing methods in ParsingCore
    â”‚     â”œâ”€[ ] ParseString(...)
    â”‚     â”œâ”€[ ] ParseBlock(...)
    â”‚     â”œâ”€[ ] ParseComment(...)
    â”‚     â””â”€[ ] ParseNumeric(...)
    â”œâ”€[ ] Refactor Tokenizer.cs to use ParsingCore
    â”œâ”€[ ] Refactor TokenParser.cs to use ParsingCore
    â”œâ”€[ ] Refactor GreenLexer.cs to use ParsingCore
    â”œâ”€[ ] Create ParsingCoreTests.cs
    â”‚     â””â”€[ ] Add comprehensive tests (target: >90% coverage)
    â””â”€[ ] Verify all three parsers produce identical results for same input

[ ] 3.2 Address Schema Nullability (4 hrs)
    File: Ast/SyntaxTree.cs
    â”œâ”€[ ] Add HasSchema property
    â”‚     â””â”€[ ] public bool HasSchema => Schema != null;
    â”œâ”€[ ] Add private RequireSchema() helper method
    â”‚     â””â”€[ ] Throw InvalidOperationException with clear message if null
    â”œâ”€[ ] Add WithSchema method
    â”‚     â””â”€[ ] public SyntaxTree WithSchema(Schema schema)
    â”œâ”€[ ] Update all schema-dependent methods to use RequireSchema()
    â”œâ”€[ ] Add comprehensive XML documentation
    â”‚     â”œâ”€[ ] Document when schema is required
    â”‚     â”œâ”€[ ] Document how to attach schema
    â”‚     â””â”€[ ] Document error behavior
    â””â”€[ ] Add unit tests for schema-related functionality

[ ] 3.3 Make Trivia Types Public (3 hrs)
    Files: Ast/GreenTrivia.cs, new Trivia.cs, Ast/RedLeaf.cs
    â”œâ”€[ ] Create Trivia.cs file
    â”‚     â”œâ”€[ ] Create public readonly struct Trivia
    â”‚     â”‚     â”œâ”€[ ] internal Trivia(GreenTrivia green) constructor
    â”‚     â”‚     â”œâ”€[ ] TriviaKind Kind property
    â”‚     â”‚     â”œâ”€[ ] string Text property
    â”‚     â”‚     â”œâ”€[ ] int Width property
    â”‚     â”‚     â””â”€[ ] override ToString()
    â”‚     â””â”€[ ] Create public enum TriviaKind
    â”‚           â”œâ”€[ ] Whitespace
    â”‚           â”œâ”€[ ] Newline
    â”‚           â”œâ”€[ ] SingleLineComment
    â”‚           â””â”€[ ] MultiLineComment
    â”œâ”€[ ] Update RedLeaf.cs
    â”‚     â”œâ”€[ ] Add IEnumerable<Trivia> LeadingTrivia property
    â”‚     â””â”€[ ] Add IEnumerable<Trivia> TrailingTrivia property
    â”œâ”€[ ] Add XML documentation to all new types
    â””â”€[ ] Add usage examples in README or docs

[ ] 3.4 Comprehensive Documentation Pass (4 hrs)
    Files: All public API files
    â”œâ”€[ ] Document Query.cs
    â”‚     â””â”€[ ] Add XML docs to all query factory methods
    â”œâ”€[ ] Document TreeWalker.cs
    â”‚     â”œâ”€[ ] Document traversal options
    â”‚     â””â”€[ ] Document filter parameters
    â”œâ”€[ ] Document NodePattern.cs
    â”‚     â””â”€[ ] Document pattern matching syntax
    â”œâ”€[ ] Document SyntaxBinder.cs
    â”‚     â””â”€[ ] Document binding process
    â”œâ”€[ ] Document Schema.cs
    â”‚     â””â”€[ ] Document schema configuration
    â”œâ”€[ ] Document SemanticNode.cs
    â”‚     â””â”€[ ] Document semantic node creation
    â””â”€[ ] Use documentation template consistently:
          â”œâ”€[ ] <summary> - Brief description
          â”œâ”€[ ] <remarks> - Detailed explanation
          â”œâ”€[ ] <example> - Code example
          â””â”€[ ] <seealso> - Related types

[ ] 3.5 Remove Obsolete APIs (30 min) âš ï¸ BREAKING
    File: Ast/SyntaxTree.cs
    â”œâ”€[ ] Remove [Obsolete] attribute from ToFullString()
    â”œâ”€[ ] Remove ToFullString() method entirely
    â”œâ”€[ ] Search for and update any internal usages
    â””â”€[ ] Document removal in CHANGELOG

[ ] 3.6 Phase 3 Release
    â”œâ”€[ ] Run full test suite
    â”œâ”€[ ] Verify API documentation is complete
    â”œâ”€[ ] Write migration guide for removed/changed APIs
    â”œâ”€[ ] Update CHANGELOG.md with all changes and breaking changes
    â”œâ”€[ ] Bump version to 0.8.0 in TinyTokenizer.csproj
    â”œâ”€[ ] Commit and tag as v0.8.0
    â”œâ”€[ ] Create GitHub release with migration notes
    â””â”€[ ] Verify NuGet package published via CI

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 4: Testing (Ongoing)
Timeline: Continuous
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[ ] 4.1 Error Recovery Test Suite (4 hrs)
    File: new TinyTokenizer.Tests/ErrorRecoveryTests.cs
    â”œâ”€[ ] Create ErrorRecoveryTests.cs file
    â”œâ”€[ ] Unclosed block tests
    â”‚     â”œâ”€[ ] Test "{" produces ErrorToken
    â”‚     â”œâ”€[ ] Test "[" produces ErrorToken
    â”‚     â”œâ”€[ ] Test "(" produces ErrorToken
    â”‚     â””â”€[ ] Test "{ { }" (nested unclosed) produces ErrorToken
    â”œâ”€[ ] Mismatched delimiter tests
    â”‚     â”œâ”€[ ] Test "{]" produces ErrorToken
    â”‚     â”œâ”€[ ] Test "[)" produces ErrorToken
    â”‚     â””â”€[ ] Test "(}" produces ErrorToken
    â”œâ”€[ ] Unclosed string tests
    â”‚     â”œâ”€[ ] Test "\"hello" produces ErrorToken or Symbol
    â”‚     â”œâ”€[ ] Test "'world" produces ErrorToken or Symbol
    â”‚     â””â”€[ ] Test "\"test\nmore\"" handles newline in string
    â””â”€[ ] Recovery tests
          â””â”€[ ] Test tokenizer continues after error token

[ ] 4.2 Unicode Test Suite (3 hrs)
    File: new TinyTokenizer.Tests/UnicodeTests.cs
    â”œâ”€[ ] Create UnicodeTests.cs file
    â”œâ”€[ ] Unicode identifier tests
    â”‚     â”œâ”€[ ] Test "å¤‰æ•°" (Japanese) recognized as identifier
    â”‚     â”œâ”€[ ] Test "Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ" (Cyrillic) recognized as identifier
    â”‚     â””â”€[ ] Test "××©×ª× ×”" (Hebrew RTL) recognized as identifier
    â”œâ”€[ ] Emoji tests
    â”‚     â”œâ”€[ ] Test "ğŸš€rocket" (emoji prefix) handled correctly
    â”‚     â””â”€[ ] Test "var_ğŸ‰" (emoji suffix) handled correctly
    â””â”€[ ] Invisible character tests
          â”œâ”€[ ] Test "\u200B" (zero-width space) handled
          â””â”€[ ] Test "\uFEFF" (BOM) handled

[ ] 4.3 Numeric Edge Cases Tests (2 hrs)
    File: TinyTokenizer.Tests/LexerParserTests.cs (extend existing)
    â”œâ”€[ ] Add numeric edge case theory tests
    â”‚     â”œâ”€[ ] Test "0" â†’ Integer
    â”‚     â”œâ”€[ ] Test "0.0" â†’ FloatingPoint
    â”‚     â”œâ”€[ ] Test ".0" â†’ FloatingPoint
    â”‚     â”œâ”€[ ] Test "0." â†’ Integer + Dot (trailing dot separate)
    â”‚     â”œâ”€[ ] Test "00123" â†’ Integer (leading zeros)
    â”‚     â””â”€[ ] Test "1.2.3" â†’ 1.2 FloatingPoint + Dot + 3 Integer

[ ] 4.4 Thread Safety Tests (3 hrs)
    File: new TinyTokenizer.Tests/ConcurrencyTests.cs
    â”œâ”€[ ] Create ConcurrencyTests.cs file
    â”œâ”€[ ] Concurrent RedNode access test
    â”‚     â”œâ”€[ ] Parse a tree once
    â”‚     â”œâ”€[ ] Spawn 100 tasks accessing Root.Children
    â”‚     â”œâ”€[ ] Each task accesses SiblingIndex, NextSibling()
    â”‚     â””â”€[ ] Verify no exceptions thrown
    â””â”€[ ] Concurrent tree parsing test
          â”œâ”€[ ] Spawn 100 tasks each parsing different input
          â”œâ”€[ ] Await all tasks
          â””â”€[ ] Verify all trees have valid Root

[ ] 4.5 Performance Benchmarks (4 hrs)
    File: TinyTokenizer.Benchmarks/
    â”œâ”€[ ] Create AllocationBenchmarks.cs
    â”‚     â”œâ”€[ ] Add [MemoryDiagnoser] attribute
    â”‚     â”œâ”€[ ] Setup small input (~1 KB)
    â”‚     â”œâ”€[ ] Setup medium input (~100 KB)
    â”‚     â”œâ”€[ ] Setup large input (~1 MB)
    â”‚     â”œâ”€[ ] Add ParseSmall benchmark
    â”‚     â”œâ”€[ ] Add ParseMedium benchmark
    â”‚     â””â”€[ ] Add ParseLarge benchmark
    â””â”€[ ] Create OperatorMatchingBenchmarks.cs
          â”œâ”€[ ] Add [MemoryDiagnoser] attribute
          â”œâ”€[ ] Add [Params(10, 50, 100)] OperatorCount
          â””â”€[ ] Add MatchOperators benchmark

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DEPENDENCIES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[ ] Add CommunityToolkit.HighPerformance 8.2.2 (Phase 2.1)
    Purpose: ArrayPoolBufferWriter<char> for zero-allocation parsing

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SUCCESS METRICS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[ ] Allocation reduction: >50% fewer allocations in parsing benchmarks
[ ] API consistency: All public types implement IFormattable where applicable
[ ] Test coverage: >85% line coverage on core parsing logic
[ ] Documentation: 100% XML doc coverage on public APIs
[ ] Performance: No regression in existing benchmarks

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RISK ASSESSMENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Risk                          | Likelihood | Impact | Mitigation
------------------------------|------------|--------|--------------------------------
Breaking change regression    | Medium     | High   | Comprehensive test suite
Performance regression        | Low        | Medium | Benchmark before/after each phase
Memory leak from pooling      | Low        | High   | Memory profiler, dispose patterns
Thread safety issues          | Medium     | High   | Dedicated concurrency tests
